"""
TOPIC ANALYZER MODULE (NOWY dla v4)
====================================
Ocena TEMATU zamiast tytu≈Çu:
- Generowanie tytu≈Ç√≥w z ocenami
- Generowanie obietnic z ocenami
- Analiza konkurencji YouTube
- Viral score prediction
- Podobne hity na kanale
"""

import re
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import numpy as np
import pandas as pd

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from youtubesearchpython import VideosSearch
    YT_SEARCH_AVAILABLE = True
except ImportError:
    YT_SEARCH_AVAILABLE = False


class TitleGenerator:
    """
    Generuje tytu≈Çy dla tematu z ocenami i uzasadnieniami.
    U≈ºywa templates + AI + wzorc√≥w z hit√≥w kana≈Çu.
    """
    
    TEMPLATES = {
        'mystery': [
            "Dlaczego {topic} do dzi≈õ pozostaje niewyja≈õnione?",
            "Tajemnica {topic}: Co naprawdƒô siƒô wydarzy≈Ço?",
            "{topic} - historia kt√≥ra wstrzƒÖsnƒô≈Ça ≈õwiatem",
            "Co ukrywa prawda o {topic}?",
            "Mroczna historia {topic}",
        ],
        'shock': [
            "SZOKUJƒÑCA prawda o {topic}",
            "Nikt nie m√≥wi o tym co NAPRAWDƒò sta≈Ço siƒô w {topic}",
            "{topic} - fakty kt√≥re zmieniƒÖ Twoje postrzeganie",
            "{topic} - najwiƒôkszy skandal w historii",
            "Dlaczego media MILCZƒÑ o {topic}?",
        ],
        'question': [
            "Co tak naprawdƒô wydarzy≈Ço siƒô w {topic}?",
            "Dlaczego {topic} nigdy nie zosta≈Ço wyja≈õnione?",
            "Kto stoi za {topic}?",
            "Czy {topic} by≈Ço zaplanowane?",
            "Jak dosz≈Ço do {topic}?",
        ],
        'emotional': [
            "Tragedia {topic}: Historia kt√≥ra ≈Çamie serce",
            "{topic} - ostatnie chwile przed katastrofƒÖ",
            "Oni wiedzieli ≈ºe zginƒÖ: {topic}",
            "{topic} - nagranie kt√≥re mrozi krew w ≈ºy≈Çach",
            "Relacja ocala≈Çych z {topic}",
        ],
        'number': [
            "5 przera≈ºajƒÖcych fakt√≥w o {topic}",
            "{topic}: 7 rzeczy kt√≥rych nie wiedzia≈Çe≈õ",
            "3 teorie o {topic} kt√≥re mogƒÖ byƒá prawdƒÖ",
            "10 minut kt√≥re zmieni≈Çy historiƒô: {topic}",
        ],
    }
    
    def __init__(self, openai_client=None, channel_data: pd.DataFrame = None):
        self.client = openai_client
        self.channel_data = channel_data
        self.hit_patterns = self._analyze_hits() if channel_data is not None else {}
    
    def _analyze_hits(self) -> Dict:
        """Analizuje wzorce z hit√≥w kana≈Çu (PASS videos)"""
        if self.channel_data is None or 'title' not in self.channel_data.columns:
            return {}
        
        df = self.channel_data.copy()
        
        # Ensure labels exist
        if 'label' not in df.columns:
            if 'views' in df.columns:
                median = df['views'].median()
                df['label'] = df['views'].apply(
                    lambda x: 'PASS' if x > median * 1.5 else 'FAIL' if x < median * 0.5 else 'BORDER'
                )
            else:
                return {}
        
        hits = df[df['label'] == 'PASS']['title'].tolist()
        
        if not hits:
            return {}
        
        patterns = {
            'avg_length': sum(len(t) for t in hits) // len(hits),
            'has_number_pct': sum(1 for t in hits if re.search(r'\d', t)) / len(hits),
            'has_question_pct': sum(1 for t in hits if '?' in t) / len(hits),
            'has_colon_pct': sum(1 for t in hits if ':' in t) / len(hits),
            'has_caps_pct': sum(1 for t in hits if re.search(r'\b[A-Z]{2,}\b', t)) / len(hits),
            'trigger_words': self._extract_trigger_words(hits),
            'hit_titles': hits[:10],  # Sample for AI context
        }
        return patterns
    
    def _extract_trigger_words(self, titles: List[str]) -> List[str]:
        """WyciƒÖga s≈Çowa kt√≥re powtarzajƒÖ siƒô w hitach (zoptymalizowane)"""
        words = {}
        stopwords = {'i', 'w', 'na', 'do', 'z', 'siƒô', 'to', 'co', 'jak', 'czy', '≈ºe', 'nie', 'o', 'za'}

        # Po≈ÇƒÖcz wszystkie tytu≈Çy i wyciƒÖgnij s≈Çowa jednym regex
        all_text = ' '.join(titles).lower()
        for word in re.findall(r'\w+', all_text):
            if len(word) > 3 and word not in stopwords:
                words[word] = words.get(word, 0) + 1

        return sorted(words.keys(), key=lambda x: words[x], reverse=True)[:30]
    
    def generate(self, topic: str, n: int = 10, use_ai: bool = True) -> List[Dict]:
        """
        Generuje tytu≈Çy dla tematu.
        
        Args:
            topic: Temat filmu (np. "Operacja Northwoods")
            n: Liczba tytu≈Ç√≥w do wygenerowania
            use_ai: Czy u≈ºywaƒá AI do generowania
            
        Returns:
            Lista {title, score, reasoning, style, source}
        """
        titles = []
        
        # 1. Template-based titles
        for style, templates in self.TEMPLATES.items():
            for template in templates[:2]:  # 2 z ka≈ºdego stylu
                title = template.format(topic=topic)
                score, reasoning = self._score_title(title)
                titles.append({
                    'title': title,
                    'score': score,
                    'reasoning': reasoning,
                    'style': style,
                    'source': 'template',
                })
        
        # 2. AI-generated titles
        if use_ai and self.client and len(titles) < n:
            ai_titles = self._generate_ai(topic, n - len(titles))
            titles.extend(ai_titles)
        
        # Sort by score
        titles = sorted(titles, key=lambda x: x['score'], reverse=True)
        
        return titles[:n]
    
    def _score_title(self, title: str) -> Tuple[int, str]:
        """
        Ocenia tytu≈Ç i zwraca (score, reasoning).
        """
        score = 50
        reasons = []
        
        # === D≈Çugo≈õƒá ===
        length = len(title)
        if 40 <= length <= 65:
            score += 10
            reasons.append("‚úÖ Optymalna d≈Çugo≈õƒá (40-65 znak√≥w)")
        elif length > 70:
            score -= 10
            reasons.append("‚ö†Ô∏è Za d≈Çugi tytu≈Ç (>70 znak√≥w)")
        elif length < 30:
            score -= 5
            reasons.append("‚ö†Ô∏è Za kr√≥tki tytu≈Ç (<30 znak√≥w)")
        
        # === Liczba ===
        if re.search(r'\d', title):
            score += 10
            reasons.append("‚úÖ Zawiera liczbƒô (konkretno≈õƒá)")
        
        # === Pytanie ===
        if '?' in title:
            score += 8
            reasons.append("‚úÖ Pytanie (buduje ciekawo≈õƒá)")
        
        # === Emocjonalne s≈Çowa ===
        emotional_words = [
            'szok', 'przera≈ºajƒÖc', 'niesamowit', 'tajemnic', 'prawda', 
            'tragedi', '≈õmierƒá', 'zgin', 'mroczn', 'ukryt', 'sekret',
            'wstrzƒÖs', 'scandal', 'afera', 'zbrodnia', 'morder'
        ]
        found_emotional = [w for w in emotional_words if w in title.lower()]
        if found_emotional:
            bonus = min(15, len(found_emotional) * 5)
            score += bonus
            reasons.append(f"‚úÖ Emocje: {', '.join(found_emotional[:3])}")
        
        # === CAPS ===
        if re.search(r'\b[A-Z]{2,}\b', title):
            score += 5
            reasons.append("‚úÖ CAPS (zwraca uwagƒô)")
        
        # === Dwukropek (struktura) ===
        if ':' in title:
            score += 5
            reasons.append("‚úÖ Struktura z dwukropkiem")
        
        # === DNA kana≈Çu ===
        if self.hit_patterns:
            trigger_words = self.hit_patterns.get('trigger_words', [])
            found_triggers = [w for w in trigger_words if w in title.lower()]
            if found_triggers:
                bonus = min(12, len(found_triggers) * 4)
                score += bonus
                reasons.append(f"‚úÖ DNA kana≈Çu: {', '.join(found_triggers[:3])}")
            
            # Match hit patterns
            if self.hit_patterns.get('has_number_pct', 0) > 0.3 and re.search(r'\d', title):
                score += 3
            if self.hit_patterns.get('has_question_pct', 0) > 0.3 and '?' in title:
                score += 3
        
        # Clamp score
        score = max(0, min(100, score))
        
        return score, ' | '.join(reasons) if reasons else 'Brak szczeg√≥lnych cech'
    
    def _generate_ai(self, topic: str, n: int) -> List[Dict]:
        """Generuje tytu≈Çy przez AI"""
        if not self.client:
            return []
        
        # Build context from hits
        hits_context = ""
        if self.hit_patterns.get('hit_titles'):
            hits_context = "\n\nPrzyk≈Çady HIT√ìW z tego kana≈Çu (na≈õladuj styl):\n"
            hits_context += "\n".join(f"- {h}" for h in self.hit_patterns['hit_titles'][:5])
        
        trigger_context = ""
        if self.hit_patterns.get('trigger_words'):
            trigger_context = f"\n\nS≈Çowa kt√≥re dzia≈ÇajƒÖ na tym kanale: {', '.join(self.hit_patterns['trigger_words'][:15])}"
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"""Jeste≈õ ekspertem od tytu≈Ç√≥w YouTube w niszy dark documentaries (mroczne dokumenty, tajemnice, zbrodnie, katastrofy).

Generujesz tytu≈Çy kt√≥re:
- BudujƒÖ CIEKAWO≈öƒÜ (curiosity gap) - widz MUSI kliknƒÖƒá
- U≈ºywajƒÖ EMOCJI: tajemnica, szok, strach, niedowierzanie
- SƒÖ KONKRETNE (liczby, daty, nazwiska)
- MajƒÖ 40-65 znak√≥w
- NIE sƒÖ tandetnym clickbaitem - muszƒÖ byƒá prawdziwe
- PasujƒÖ do stylu kana≈Çu{hits_context}{trigger_context}"""},
                    {"role": "user", "content": f"""Wygeneruj {n} unikalnych tytu≈Ç√≥w dla tematu: "{topic}"

Ka≈ºdy tytu≈Ç powinien mieƒá inny styl (pytanie, szok, emocje, liczby, tajemnica).

Odpowiedz TYLKO w formacie JSON:
{{"titles": [
  {{"title": "...", "score": 70-95, "reasoning": "dlaczego dobry", "style": "mystery/shock/emotional/question/number"}}
]}}"""}
                ],
                response_format={"type": "json_object"},
                temperature=0.8,
            )
            
            result = json.loads(response.choices[0].message.content)
            titles = result.get('titles', [])
            
            for t in titles:
                t['source'] = 'ai'
                # Recalculate score with our logic
                calculated_score, calculated_reasoning = self._score_title(t['title'])
                t['calculated_score'] = calculated_score
                # Use max of AI score and calculated score
                t['score'] = max(t.get('score', 0), calculated_score)
                t['reasoning'] = f"{t.get('reasoning', '')} | {calculated_reasoning}"
            
            return titles
            
        except Exception as e:
            print(f"AI title generation error: {e}")
            return []


class PromiseGenerator:
    """
    Generuje obietnice (hooki pod tytu≈Çem) z ocenami.
    """
    
    TEMPLATES = [
        "To co odkryjesz zmieni Twoje postrzeganie tego tematu na zawsze.",
        "Historia kt√≥rƒÖ przez lata ukrywano przed opiniƒÖ publicznƒÖ.",
        "Fakty kt√≥re sprawiƒÖ ≈ºe ju≈º nigdy nie spojrzysz na to tak samo.",
        "Dlaczego odpowiedzialni za to milczƒÖ do dzi≈õ?",
        "Dowody kt√≥re zmieniajƒÖ wszystko co wiedzieli≈õmy.",
        "To nie by≈Ç przypadek. To by≈Ç plan.",
        "Nikt nie m√≥wi o tym co naprawdƒô siƒô wydarzy≈Ço.",
        "Prawda jest znacznie mroczniejsza ni≈º oficjalna wersja.",
        "Co ukrywa siƒô za zamkniƒôtymi drzwiami?",
        "Relacja ≈õwiadk√≥w kt√≥rych nikt nie chcia≈Ç s≈Çuchaƒá.",
        "Dokumenty kt√≥re mia≈Çy nigdy nie ujrzeƒá ≈õwiat≈Ça dziennego.",
        "Historia kt√≥ra zmieni Twoje rozumienie ≈õwiata.",
    ]
    
    def __init__(self, openai_client=None):
        self.client = openai_client
    
    def generate(self, title: str, topic: str, n: int = 5, use_ai: bool = True) -> List[Dict]:
        """
        Generuje obietnice dla tytu≈Çu.
        
        Returns:
            Lista {promise, score, reasoning}
        """
        promises = []
        
        # Template-based
        for template in self.TEMPLATES[:n]:
            score, reasoning = self._score_promise(template, title)
            promises.append({
                'promise': template,
                'score': score,
                'reasoning': reasoning,
                'source': 'template',
            })
        
        # AI-generated
        if use_ai and self.client:
            ai_promises = self._generate_ai(title, topic, n)
            promises.extend(ai_promises)
        
        # Sort and return top n
        promises = sorted(promises, key=lambda x: x['score'], reverse=True)
        return promises[:n]
    
    def _score_promise(self, promise: str, title: str) -> Tuple[int, str]:
        """Ocenia obietnicƒô"""
        score = 50
        reasons = []
        
        # D≈Çugo≈õƒá
        if 50 <= len(promise) <= 150:
            score += 10
            reasons.append("‚úÖ Dobra d≈Çugo≈õƒá")
        elif len(promise) > 200:
            score -= 10
            reasons.append("‚ö†Ô∏è Za d≈Çuga")
        elif len(promise) < 40:
            score -= 5
            reasons.append("‚ö†Ô∏è Za kr√≥tka")
        
        # Buduje napiƒôcie
        tension_words = ['ukryt', 'tajemnic', 'prawda', 'odkryj', 'zmieni', 'nigdy', 'nikt', 'sekret', 'mroczn']
        found = [w for w in tension_words if w in promise.lower()]
        if found:
            bonus = min(15, len(found) * 5)
            score += bonus
            reasons.append(f"‚úÖ Napiƒôcie: {', '.join(found[:3])}")
        
        # Nie powtarza tytu≈Çu
        title_words = set(w.lower() for w in title.split() if len(w) > 3)
        promise_words = set(w.lower() for w in promise.split() if len(w) > 3)
        overlap = len(title_words & promise_words)
        
        if overlap < 2:
            score += 10
            reasons.append("‚úÖ Dodaje nowƒÖ warto≈õƒá (nie powtarza)")
        elif overlap > 3:
            score -= 5
            reasons.append("‚ö†Ô∏è Powtarza s≈Çowa z tytu≈Çu")
        
        # Konkretno≈õƒá
        if any(word in promise.lower() for word in ['dokument', 'dowod', '≈õwiadek', 'relacj', 'nagran']):
            score += 5
            reasons.append("‚úÖ Konkretna obietnica")
        
        return max(0, min(100, score)), ' | '.join(reasons)
    
    def _generate_ai(self, title: str, topic: str, n: int) -> List[Dict]:
        """Generuje obietnice przez AI"""
        if not self.client:
            return []
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": """Jeste≈õ ekspertem od YouTube hooks dla dark documentaries.

Generujesz OBIETNICE (1-2 zdania pod tytu≈Çem) kt√≥re:
- BudujƒÖ NAPIƒòCIE i ciekawo≈õƒá
- NIE zdradzajƒÖ rozwiƒÖzania/ko≈Ñca
- ObiecujƒÖ WARTO≈öƒÜ (co widz siƒô dowie)
- U≈ºywajƒÖ emocji
- SƒÖ KOMPLEMENTARNE do tytu≈Çu (nie powtarzajƒÖ go)
- SƒÖ wiarygodne (nie tandetny clickbait)"""},
                    {"role": "user", "content": f"""Tytu≈Ç filmu: "{title}"
Temat: "{topic}"

Wygeneruj {n} unikalnych obietnic.

JSON: {{"promises": [{{"promise": "...", "score": 60-90, "reasoning": "dlaczego dzia≈Ça"}}]}}"""}
                ],
                response_format={"type": "json_object"},
                temperature=0.7,
            )
            
            result = json.loads(response.choices[0].message.content)
            promises = result.get('promises', [])
            
            for p in promises:
                p['source'] = 'ai'
            
            return promises
            
        except Exception as e:
            print(f"AI promise generation error: {e}")
            return []


class CompetitorAnalyzer:
    """Analizuje konkurencjƒô na YouTube dla tematu"""
    
    def __init__(self):
        self.available = YT_SEARCH_AVAILABLE
    
    def analyze(self, topic: str, max_results: int = 20) -> Dict:
        """
        Analizuje konkurencjƒô dla tematu na YouTube.
        
        Returns:
            Dict z saturation, opportunity_score, top_videos, recommendation
        """
        if not self.available:
            return {
                'error': 'youtube-search-python niedostƒôpne',
                'saturation': 'UNKNOWN',
                'opportunity_score': 50,
                'top_videos': [],
                'recommendation': 'Zainstaluj: pip install youtube-search-python',
            }
        
        result = {
            'topic': topic,
            'total_videos': 0,
            'high_view_videos': 0,
            'recent_videos': 0,
            'top_videos': [],
            'saturation': 'MEDIUM',
            'opportunity_score': 50,
            'recommendation': '',
        }
        
        try:
            # Search for topic
            search = VideosSearch(f"{topic} polski dokumentalny", limit=max_results, region='PL')
            videos = search.result().get('result', [])
            
            result['total_videos'] = len(videos)
            
            for vid in videos:
                view_text = vid.get('viewCount', {}).get('text', '0')
                views = self._parse_views(view_text)
                published = vid.get('publishedTime', '')
                
                # Count high-view videos
                if views >= 50000:
                    result['high_view_videos'] += 1
                
                # Count recent videos
                if any(x in published.lower() for x in ['dzie≈Ñ', 'dni', 'day', 'tydzie≈Ñ', 'tygodni', 'week', 'miesiƒÖc', 'month']):
                    result['recent_videos'] += 1
                
                result['top_videos'].append({
                    'title': vid.get('title', ''),
                    'views': views,
                    'channel': vid.get('channel', {}).get('name', ''),
                    'published': published,
                    'duration': vid.get('duration', ''),
                    'link': vid.get('link', ''),
                })
            
            # Sort by views
            result['top_videos'] = sorted(result['top_videos'], key=lambda x: x['views'], reverse=True)[:10]
            
            # Calculate saturation and opportunity
            high_views = result['high_view_videos']
            recent = result['recent_videos']
            
            if high_views >= 5:
                result['saturation'] = 'HIGH'
                result['opportunity_score'] = 25
                result['recommendation'] = "üî¥ WYSOKA konkurencja - temat mocno eksploatowany. Potrzebujesz unikalnego kƒÖta lub ≈õwie≈ºych informacji."
            elif high_views >= 3:
                result['saturation'] = 'MEDIUM'
                result['opportunity_score'] = 55
                result['recommendation'] = "üü° ≈öREDNIA konkurencja - jest miejsce, ale musisz siƒô wyr√≥≈ºniƒá."
            else:
                result['saturation'] = 'LOW'
                result['opportunity_score'] = 80
                result['recommendation'] = "üü¢ NISKA konkurencja - ≈õwietna okazja! Ma≈Ço film√≥w o tym temacie."
            
            # Bonus if no recent videos
            if recent == 0 and result['total_videos'] > 0:
                result['opportunity_score'] += 15
                result['recommendation'] += " ‚ú® Brak ≈õwie≈ºych film√≥w - idealne okno czasowe!"
            
            result['opportunity_score'] = min(100, result['opportunity_score'])
            
        except Exception as e:
            result['error'] = str(e)
            result['recommendation'] = f"B≈ÇƒÖd: {e}"
        
        return result
    
    def _parse_views(self, view_text: str) -> int:
        """Parsuje tekst views na int"""
        try:
            text = view_text.lower().replace(' ', '').replace(',', '').replace('.', '')
            
            multiplier = 1
            if 'mln' in text or 'm' in text:
                multiplier = 1000000
                text = re.sub(r'(mln|m)', '', text)
            elif 'tys' in text or 'k' in text:
                multiplier = 1000
                text = re.sub(r'(tys|k)', '', text)
            
            number = float(re.sub(r'[^\d.]', '', text) or 0)
            return int(number * multiplier)
        except (ValueError, TypeError):
            return 0


class ViralScorePredictor:
    """Przewiduje potencja≈Ç viralowy tematu/tytu≈Çu"""
    
    VIRAL_FACTORS = {
        'emotional_intensity': {
            'keywords': ['szok', 'niesamowit', 'niewiarygod', 'przera≈ºajƒÖc', 'wstrzƒÖsajƒÖc', 'poruszajƒÖc'],
            'weight': 15,
        },
        'controversy': {
            'keywords': ['skandal', 'afera', 'oszust', 'k≈Çamst', 'ukrywa', 'cenzur', 'zakazan'],
            'weight': 12,
        },
        'mystery': {
            'keywords': ['tajemnic', 'zagadk', 'niewyja≈õnion', 'zaginion', 'sekret', 'odkry'],
            'weight': 10,
        },
        'tragedy': {
            'keywords': ['tragedi', '≈õmierƒá', 'zgin', 'ofiar', 'katastro', 'wypadek'],
            'weight': 10,
        },
        'relatability': {
            'keywords': ['polsk', 'nasz', 'tw√≥j', 'ka≈ºdy'],
            'weight': 8,
        },
        'urgency': {
            'keywords': ['teraz', 'w≈Ça≈õnie', 'pilne', 'dzi≈õ'],
            'weight': 5,
        },
    }
    
    def __init__(self, channel_data: pd.DataFrame = None):
        self.channel_data = channel_data
        self.benchmarks = self._calculate_benchmarks() if channel_data is not None else {}
    
    def _calculate_benchmarks(self) -> Dict:
        """Oblicza benchmarki z danych kana≈Çu"""
        if self.channel_data is None or 'views' not in self.channel_data.columns:
            return {}
        
        df = self.channel_data
        return {
            'median_views': df['views'].median(),
            'top_10_pct_views': df['views'].quantile(0.9),
            'avg_retention': df['retention'].mean() if 'retention' in df.columns else None,
        }
    
    def predict(self, title: str, topic: str, competition: Dict = None) -> Dict:
        """
        Przewiduje viral score.
        
        Returns:
            Dict z viral_score (0-100), verdict, factors, recommendation
        """
        score = 50
        factors = []
        
        text = f"{title} {topic}".lower()
        
        # Check viral factors
        for factor_name, factor_data in self.VIRAL_FACTORS.items():
            keywords = factor_data['keywords']
            weight = factor_data['weight']
            
            found = [kw for kw in keywords if kw in text]
            if found:
                bonus = min(weight, len(found) * (weight // 2))
                score += bonus
                factors.append({
                    'factor': factor_name,
                    'found': found,
                    'bonus': f"+{bonus}",
                })
        
        # Competition factor
        if competition:
            saturation = competition.get('saturation', 'MEDIUM')
            if saturation == 'LOW':
                score += 15
                factors.append({'factor': 'low_competition', 'found': ['Niska konkurencja'], 'bonus': '+15'})
            elif saturation == 'HIGH':
                score -= 10
                factors.append({'factor': 'high_competition', 'found': ['Wysoka konkurencja'], 'bonus': '-10'})
        
        # Length factor
        if 40 <= len(title) <= 65:
            score += 5
            factors.append({'factor': 'optimal_length', 'found': ['Optymalna d≈Çugo≈õƒá'], 'bonus': '+5'})
        
        # Clamp
        score = max(0, min(100, score))
        
        # Verdict
        if score >= 75:
            verdict = "üöÄ WYSOKI potencja≈Ç viralowy! Ten temat mo≈ºe wybuchnƒÖƒá."
        elif score >= 60:
            verdict = "üìà DOBRY potencja≈Ç - mo≈ºe przyciƒÖgnƒÖƒá nowych widz√≥w."
        elif score >= 45:
            verdict = "‚û°Ô∏è STANDARDOWY zasiƒôg - solidny temat dla sta≈Çych widz√≥w."
        else:
            verdict = "üìâ NISKI potencja≈Ç - rozwa≈º inny kƒÖt lub temat."
        
        return {
            'viral_score': score,
            'verdict': verdict,
            'factors': factors,
            'recommendation': self._generate_recommendation(score, factors),
        }
    
    def _generate_recommendation(self, score: int, factors: List[Dict]) -> str:
        """Generuje rekomendacjƒô jak zwiƒôkszyƒá viral score"""
        found_factors = [f['factor'] for f in factors]
        suggestions = []
        
        if 'emotional_intensity' not in found_factors:
            suggestions.append("Dodaj emocjonalne s≈Çowa (szokujƒÖce, niesamowite)")
        if 'mystery' not in found_factors:
            suggestions.append("Dodaj element tajemnicy")
        if 'controversy' not in found_factors and score < 60:
            suggestions.append("Rozwa≈º kontrowersyjny kƒÖt")
        
        if suggestions:
            return "üí° " + " | ".join(suggestions[:2])
        elif score >= 70:
            return "‚úÖ Wszystkie kluczowe elementy obecne!"
        else:
            return "üîç Sprawd≈∫ konkurencjƒô i timing"


class SimilarVideosFinder:
    """Znajduje podobne filmy na kanale"""
    
    def __init__(self, channel_data: pd.DataFrame):
        self.channel_data = channel_data
    
    def find(self, topic: str, title: str = None, top_n: int = 5) -> List[Dict]:
        """Znajduje podobne filmy z kana≈Çu"""
        if self.channel_data is None or 'title' not in self.channel_data.columns:
            return []
        
        df = self.channel_data.copy()
        search_text = f"{topic} {title or ''}".lower()
        keywords = [w for w in search_text.split() if len(w) > 3]
        
        results = []
        for idx, row in df.iterrows():
            row_title = str(row.get('title', '')).lower()
            
            # Count keyword matches
            match_count = sum(1 for kw in keywords if kw in row_title)
            
            if match_count > 0:
                label = row.get('label', 'BORDER')
                views = row.get('views', 0)
                retention = row.get('retention', 0)
                
                # Weight by label
                weight = 2.0 if label == 'PASS' else 0.5 if label == 'FAIL' else 1.0
                
                results.append({
                    'title': row.get('title', ''),
                    'views': views,
                    'retention': retention,
                    'label': label,
                    'similarity_score': match_count * weight,
                    'insight': self._generate_insight(label, views, retention),
                    'video_id': row.get('video_id', ''),
                })
        
        # Sort by similarity
        results = sorted(results, key=lambda x: x['similarity_score'], reverse=True)
        return results[:top_n]
    
    def _generate_insight(self, label: str, views: int, retention: float) -> str:
        """Generuje insight dla podobnego filmu"""
        if label == 'PASS':
            return f"‚úÖ HIT - {views:,} views, {retention:.0f}% retention. Na≈õladuj podej≈õcie!"
        elif label == 'FAIL':
            return f"‚ùå S≈ÅABY - {views:,} views. Unikaj podobnego podej≈õcia."
        else:
            return f"üü° ≈öREDNI - {views:,} views, {retention:.0f}% retention."


class TopicEvaluator:
    """
    G≈Ç√≥wna klasa oceniajƒÖca TEMAT.
    ≈ÅƒÖczy wszystkie modu≈Çy w jeden wynik.
    """
    
    def __init__(self, openai_client=None, channel_data: pd.DataFrame = None):
        self.client = openai_client
        self.channel_data = channel_data
        
        # Initialize sub-modules
        self.title_generator = TitleGenerator(openai_client, channel_data)
        self.promise_generator = PromiseGenerator(openai_client)
        self.competitor_analyzer = CompetitorAnalyzer()
        self.viral_predictor = ViralScorePredictor(channel_data)
        self.similar_finder = SimilarVideosFinder(channel_data) if channel_data is not None else None
    
    def evaluate(self, topic: str, n_titles: int = 10, n_promises: int = 5) -> Dict:
        """
        Pe≈Çna ocena tematu.
        
        Returns:
            Kompletny wynik z tytu≈Çami, obietnicami, konkurencjƒÖ, viral score, etc.
        """
        result = {
            'topic': topic,
            'timestamp': datetime.now().isoformat(),
            'titles': [],
            'selected_title': None,
            'promises': [],
            'competition': {},
            'viral_score': {},
            'similar_hits': [],
            'overall_score': 0,
            'recommendation': '',
        }
        
        # 1. Generate titles
        result['titles'] = self.title_generator.generate(topic, n=n_titles)
        
        if result['titles']:
            result['selected_title'] = result['titles'][0]  # Best one
            
            # 2. Generate promises for best title
            result['promises'] = self.promise_generator.generate(
                result['selected_title']['title'],
                topic,
                n=n_promises
            )
        
        # 3. Analyze competition
        result['competition'] = self.competitor_analyzer.analyze(topic)
        
        # 4. Predict viral score
        best_title = result['selected_title']['title'] if result['selected_title'] else topic
        result['viral_score'] = self.viral_predictor.predict(
            best_title, topic, result['competition']
        )
        
        # 5. Find similar videos
        if self.similar_finder:
            result['similar_hits'] = self.similar_finder.find(topic, best_title)
        
        # 6. Calculate overall score
        title_score = result['selected_title']['score'] if result['selected_title'] else 50
        competition_score = result['competition'].get('opportunity_score', 50)
        viral_score = result['viral_score'].get('viral_score', 50)
        
        result['overall_score'] = int(
            title_score * 0.35 +
            competition_score * 0.30 +
            viral_score * 0.35
        )
        
        # 7. Generate recommendation
        result['recommendation'] = self._generate_recommendation(result)
        
        return result
    
    def _generate_recommendation(self, result: Dict) -> str:
        """Generuje ko≈ÑcowƒÖ rekomendacjƒô"""
        score = result['overall_score']
        competition = result['competition'].get('saturation', 'MEDIUM')
        viral = result['viral_score'].get('viral_score', 50)
        
        if score >= 75:
            rec = "üü¢ PUBLIKUJ! ≈öwietny temat z wysokim potencja≈Çem."
        elif score >= 60:
            rec = "üü° DOBRY temat. Dopracuj tytu≈Ç i hook wg sugestii."
        elif score >= 45:
            rec = "üü† ≈öREDNI potencja≈Ç. Rozwa≈º inny kƒÖt lub lepszy timing."
        else:
            rec = "üî¥ S≈ÅABY temat. Poszukaj lepszego lub zmie≈Ñ podej≈õcie."
        
        # Additional notes
        if competition == 'HIGH':
            rec += " ‚ö†Ô∏è Wysoka konkurencja - potrzebujesz unikalnego kƒÖta."
        if competition == 'LOW':
            rec += " ‚ú® Niska konkurencja - to Twoja szansa!"
        if viral >= 70:
            rec += " üöÄ Wysoki potencja≈Ç viralowy!"
        
        return rec


# =============================================================================
# FACTORY FUNCTION
# =============================================================================

def get_topic_evaluator(openai_client=None, channel_data=None) -> TopicEvaluator:
    """Factory function to get TopicEvaluator instance"""
    return TopicEvaluator(openai_client, channel_data)
